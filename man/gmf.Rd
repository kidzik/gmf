% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gmf.R
\name{gmf}
\alias{gmf}
\title{Factorize a matrix of non-Gaussian observations}
\usage{
gmf(
  Y,
  X = NULL,
  family = poisson(),
  p = 2,
  penaltyU = 1,
  penaltyV = 0,
  penaltyBeta = 0,
  intercept = FALSE,
  maxIter = NULL,
  gamma = NULL,
  tol = 0.001,
  damping = 0,
  init = "random",
  normalize_uv = TRUE,
  verbose = TRUE,
  method = "airwls",
  airwls.internal.steps = 1,
  parallel = 1
)
}
\arguments{
\item{Y}{matrix of responses}

\item{X}{matrix of fixed effects}

\item{family}{a family as in the \code{\link{glm}} interface}

\item{p}{number of random effects to estimate (default 2)}

\item{penaltyU}{penalty on latent scores}

\item{penaltyV}{penalty on latent variables}

\item{penaltyBeta}{penalty on fixed-effect coefficients}

\item{intercept}{should the model include the intercept}

\item{maxIter}{maximum number of Newton steps iterations}

\item{gamma}{step size in the newton algorithm}

\item{tol}{threshold for the stopping criterium (a relative change in deviance)}

\item{damping}{regularization parameter of the hessian in the direct quasi Newton}

\item{init}{initialization of model parameters: "random" (default) or "svd"}

\item{normalize_uv}{normalize UV to iid gaussian U and upper diagonal V with a positive diagonal}

\item{verbose}{output deviance every 10 iterations}

\item{method}{"airwls" (Alternating Iterative Reweighted Least Squares, default) or "newton" (Quasi-Newton)}

\item{airwls.internal.steps}{number of steps of the IRWLS in each inner loop for AIRWLS}

\item{parallel}{number of cores on which to run AIRWLS iterations}
}
\value{
Returns model parameters and its deviance
\itemize{
\item beta - fixed-effect coefficients
\item U - latent scores
\item V - latent vectors
\item fit - fitted matrix of means
\item deviance - model mean deviance
}
}
\description{
Fit a GLLVM model, i.e. decompose a matrix of non-Gaussian responses to low-rank matrices. This is an alternative to PCA and SVD
in situations where observed data do not follow Gaussian distribution. This approach is particularly useful when we observe
responses following a distribution from the exponential family, such as
binomial (i.e. binary, e.g. species present or not at certain locations), nonnegative-binomial (e.g. count data
of genes observed in patients), Poisson, etc. In such cases PCA and similar techniques can lead to unreliable results
when normality assumptions are violated. If additional information for each observational unit are present,
these data can be incorporated into the model as a linear fixed effect. Moreover, users of this package
have freedom to chose the number of underlying latent factors to estimate.
}
\details{
To fit the model, the function optimizes a penalized quasi-likelihood function using the Newton method (gradient descent). Newton step
is performed using either a direct differntiation with diagonal approximation of Hessians (for fast computation), or using
Alternating Iterative Reweighted Least Squares (AIRWLS, default). AIRWLS leverages the fact that the problem for each row
and column can be seen as a regular GLM problem.

We assume that observed matrix of \eqn{n \times m}responses follow the distribution
\eqn{y_{ij} | \mu_{ij} \sim \mathcal{F}(\mu_{ij},\phi_j)}
where \eqn{g} is a link function, i.e. \eqn{g(\mu_{ij}) = \eta_{ij} = \beta_{0j} + x_i'\beta_j + u_i'\lambda_j} for a
set distribution \eqn{\mathcal{F}}. Quantities \eqn{\beta}, \eqn{\lambda} and \eqn{\phi} are model parameters. \eqn{\beta}
correspond to \eqn{d} fixed-effects or known factors. \eqn{\lambda} are  \eqn{p} random-effects or unobserved factors. \eqn{\phi}
are dispersion parameters. The parameter \eqn{p} is selected by the user.

We find model parameters by optimizing
\deqn{L(\Psi) =-\sum_{i=1}^n \sum_{j=1}^m (y_{ij}\tilde\eta_{ij} - b(\tilde\eta_{ij})) + \frac{\lambda_U}{2} \sum_{i=1}^n u_i'u_i}
where \eqn{b} is the cumulant function of the given distribution in the exponential family and \eqn{\lambda_U} is the
weight for the L2 penalty on \eqn{U}. This is \eqn{1} and can be tuned with \code{penaltyU}, together with additional penalty
of the same form on V (\code{penaltyV}) or beta coefficients (\code{penaltyBeta}).

Each step of the Newton algorithm takes form
\deqn{\theta_{t+1} = \theta_{t} + s [-d^2L(\theta_t)]^{-1} \nabla L(\theta_t)}
where \eqn{\theta_t} is the parameter we are optimizing (\eqn{U},\eqn{V}, or \eqn{\beta}), \eqn{d^2L} stands for Hessians
while \eqn{\nabla L} is the gradient of L. In \code{"newton"} method these quantities are approximated directly, while
in \code{"newton"} an update step is transformed to a weighted linear regression problem as in GLMs.

We perform at most \code{maxIter} steps of the Newton algorithm with the stepsize \code{gamma}, stopping if the relative
change in deviance is smaller than \code{tol}. After performing optimization, the latent scores and variables are rotated
such that the matrix \eqn{U} has the covariance matrix equal to identity, while the matrix \eqn{V} is upper-triangular
with positive elements on the diagonal.

To initiate the Newton algorithm we either draw random variables (if \code{init} is \code{"random"}) or we regress out the
fixed effects and perform the SVD on the residuals. Matrices U and V derived from SVD are then used as initialization points
for the latent scores and variables.

Each of the two optimization methods takes additional parameters. In the AIRWLS method we can specify the number
of steps of each of the internal optimizations (i.e. IRWLS steps) of \eqn{U}, \eqn{V}, and \eqn{\beta}, before we move on
to optimizing the next parameter. By default \code{airwls.internal.steps=1} corresponding to only one step of the internal
optimization and then passing to the next iteration of the external AIRWLS loop. The parameter \code{parallel} is used
to distribute computations of coefficients for separate collumns and rows to different CPU cores, effectively speeding up
the computation. In the Newton method, damping parameter adds a diagonal regularization term to Hessians, making the
inversion of Hessians more stable.
}
\examples{
# In this example we simulate synthetic matrix of resoponses from the Binomial
# family and we fit the GLLVM model 
data = gmf.simulate(family=binomial())

# Fit a GLLVM model using Newton method
model = gmf(data$Y)

# Plot scores
plot(model$u)

# Compute the mean deviance
print(matrix.deviance(model$fit, data$Y, model$family))
}
\references{
Lukasz Kidzinski, Francis K.C. Hui, David I. Warton, Trevor J. Hastie
\emph{Generalized Matrix Factorization}
arXiv, 2020
}
